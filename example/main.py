import pystats2md
from pystats2md.stats_subset import *
from pystats2md.stats_file import *
from pystats2md.report import *
from pystats2md.micro_bench import *
from pystats2md.aggregation import *

f = StatsFile('example/benchmarks.json')
r = Report()

r.add('# Database performance')
r.add('This benchmark report was generated by [main.py](main.py).')

r.add(f.table(
    rows='database_name',
    cols='benchmark_name',
    cells='operations_per_second',
))

r.add('## Lets add some colors!')

r.add(f.table(
    rows='database_name',
    cols='benchmark_name',
    cells='operations_per_second',
).add_emoji(impressive_gain=1.5))

r.add('## Or a ranking?')

r.add(f.table(
    rows='database_name',
    cols='benchmark_name',
    cells='operations_per_second',
).add_ranking(column='Upsert Entry'))

r.add('## Define a baseline and see the gains!')

r.add(StatsSubset(f).to_table(
    row_name_property='database_name',
    col_name_property='benchmark_name',
    cell_content_property='operations_per_second',
    row_names=['SQLite', 'MySQL', 'PostgreSQL', 'MongoDB'],
    col_names=['Find Entry'],
).add_gains())



r.add(StatsSubset(f).grouped(
    *['database_name', 'benchmark_name'], 
    **{'operations_per_second': Aggregation.take_max}
).to_table(
    row_name_property='database_name',
    col_name_property='benchmark_name',
    cell_content_property='operations_per_second',
).plot(
    title='DB Performance', 
    show_values=True,
))

r.add(StatsSubset(f).grouped(
    *['database_name', 'benchmark_name'], 
    **{'operations_per_second': Aggregation.take_mean}
).to_table(
    row_name_property='database_name',
    col_name_property='benchmark_name',
    cell_content_property='operations_per_second',
    row_names=['SQLite', 'MySQL', 'PostgreSQL', 'MongoDB'],
).normalize_values().plot(
    title='DB Performance (Normalized)', 
    show_values=False,
))

r.print_to('example/README.md')
