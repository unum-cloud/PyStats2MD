import pystats2md
from pystats2md.stats_subset import *
from pystats2md.stats_file import *
from pystats2md.report import *
from pystats2md.micro_bench import *
from pystats2md.aggregation import *

f = StatsFile('example/benchmarks.json')
r = Report()

r.add('# Database performance')
r.add('This benchmark report was generated by [main.py](main.py).')

r.add(f.table(
    rows='database_name',
    cols='benchmark_name',
    cells='operations_per_second',
))

r.add('## Lets add some colors!')

r.add(f.table(
    rows='database_name',
    cols='benchmark_name',
    cells='operations_per_second',
).add_emoji(impressive_gain=1.5))

r.add('## Or a ranking?')

r.add(f.table(
    rows='database_name',
    cols='benchmark_name',
    cells='operations_per_second',
).add_ranking(column='Upsert Entry'))

r.add('## Define a baseline and see the gains!')

r.add(StatsSubset(f).table(
    row_name_property='database_name',
    col_name_property='benchmark_name',
    cell_content_property='operations_per_second',
    row_names=['SQLite', 'MySQL', 'PostgreSQL', 'MongoDB'],
    col_names=['Find Entry'],
).add_gains())

r.add('## Render charts with Plotly!')

r.add(f.plot(
    title='DB Performance (Ops/Sec)',
    variants='database_name',
    groups='benchmark_name',
    values='operations_per_second',
    show_values=True,
))

r.add(StatsSubset(f).grouped(
    *['database_name', 'benchmark_name'],
    **{'operations_per_second': Aggregation.take_mean}
).table(
    row_name_property='database_name',
    col_name_property='benchmark_name',
    cell_content_property='operations_per_second',
    row_names=['SQLite', 'MySQL', 'PostgreSQL', 'MongoDB'],
).normalize_values().plot(
    title='DB Performance (Normalized)',
    show_values=False,
))

r.print_to('example/README.md')
